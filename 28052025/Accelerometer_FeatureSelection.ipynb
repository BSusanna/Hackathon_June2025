{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP1KvJhbMFb4",
        "outputId": "d9b9a775-e862-4971-91f5-4acd1ea6dae7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define your desired path\n",
        "path = '/content/drive/My Drive/HackathonJune2025/28april'\n",
        "\n",
        "# Change the current working directory to the new path\n",
        "os.chdir(path)\n",
        "\n",
        "# Verify the current working directory\n",
        "print(\"Current Working Directory:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgJ4czAuL_m8",
        "outputId": "3a949b02-8573-40cc-8bc8-1cdb762a3b33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content/drive/My Drive/HackathonJune2025/28april\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rZUaQYzKZMGP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import logging\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from datasets import import_accelerometer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waMKAfZRLuI4",
        "outputId": "adc8b741-e30e-45a6-d1f2-063ac2f1cfbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:5718: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  values = array(values, copy=None, ndmin=arr.ndim, dtype=arr.dtype)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = import_accelerometer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "Jnd6mjqiMUDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to exploit the same models: Random Forests, Gradient Boosting, Logistic Regression"
      ],
      "metadata": {
        "id": "bhLkyTW0OcgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "def backward_selection(X, y):\n",
        "    \"\"\"\n",
        "    Perform backward selection to identify the best features for classification.\n",
        "\n",
        "    Parameters:\n",
        "    - X: DataFrame of features\n",
        "    - y: Target array with class labels\n",
        "\n",
        "    Returns:\n",
        "    - selected_features: List of selected feature names\n",
        "    \"\"\"\n",
        "    features = X.columns.tolist()\n",
        "    selected_features = features.copy()\n",
        "    best_score = -np.inf\n",
        "\n",
        "    while len(selected_features) > 1:\n",
        "        scores = {}\n",
        "        for feature in selected_features:\n",
        "            subset_features = [f for f in selected_features if f != feature]\n",
        "            X_subset = X[subset_features]\n",
        "            model = RandomForestClassifier(random_state=42)\n",
        "            score = cross_val_score(model, X_subset, y, cv=5, scoring='accuracy').mean() #5-fold CROSS-VALIDATION\n",
        "            scores[feature] = score\n",
        "        worst_feature = min(scores, key=scores.get)\n",
        "        if scores[worst_feature] > best_score:\n",
        "            best_score = scores[worst_feature]\n",
        "            selected_features.remove(worst_feature)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print(\"Backward Selection - Selected Features:\", selected_features)\n",
        "    return selected_features\n",
        "\n",
        "def forward_selection(X, y):\n",
        "    \"\"\"\n",
        "    Perform forward selection to identify the best features for classification.\n",
        "\n",
        "    Parameters:\n",
        "    - X: DataFrame of features\n",
        "    - y: Target array with class labels\n",
        "\n",
        "    Returns:\n",
        "    - selected_features: List of selected feature names\n",
        "    \"\"\"\n",
        "    features = X.columns.tolist()\n",
        "    selected_features = []\n",
        "    best_score = -np.inf\n",
        "\n",
        "    while len(selected_features) < len(features):\n",
        "        scores = {}\n",
        "        for feature in features:\n",
        "            if feature not in selected_features:\n",
        "                subset_features = selected_features + [feature]\n",
        "                X_subset = X[subset_features]\n",
        "                model = RandomForestClassifier(random_state=42)\n",
        "                score = cross_val_score(model, X_subset, y, cv=5, scoring='accuracy').mean() #5-fold CROSS-VALIDATION\n",
        "                scores[feature] = score\n",
        "        best_feature = max(scores, key=scores.get)\n",
        "        if scores[best_feature] > best_score:\n",
        "            best_score = scores[best_feature]\n",
        "            selected_features.append(best_feature)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print(\"Forward Selection - Selected Features:\", selected_features)\n",
        "    return selected_features\n",
        "\n",
        "# Assuming X_train contains features and Y_train is the target with class labels\n",
        "selected_features_bw = backward_selection(pd.DataFrame(X_train), Y_train)\n",
        "selected_features_fw = forward_selection(pd.DataFrame(X_train), Y_train)\n"
      ],
      "metadata": {
        "id": "hY3HByrYMTSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894fe540-536f-425c-d14f-adb112f1b4e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backward Selection - Selected Features: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
            "Forward Selection - Selected Features: [10, 12, 0, 8, 14, 6, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame if not already\n",
        "if not isinstance(X_train, pd.DataFrame):\n",
        "    X_train = pd.DataFrame(X_train, columns=[f\"Feature_{i}\" for i in range(X_train.shape[1])])\n",
        "print(\"Column Names in X_train:\")\n",
        "print(X_train.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoOaNFgpJhMm",
        "outputId": "a6d1d536-356e-4660-a9b4-fb67a51b36f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names in X_train:\n",
            "['Feature_0', 'Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10', 'Feature_11', 'Feature_12', 'Feature_13', 'Feature_14', 'Feature_15', 'Feature_16', 'Feature_17']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_features(X_train, X_val, X_test, selected_features):\n",
        "    \"\"\"\n",
        "    Filter the datasets to include only the selected features.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train, X_val, X_test: Datasets (either pandas DataFrames or NumPy arrays).\n",
        "    - selected_features: List of selected feature indices.\n",
        "\n",
        "    Returns:\n",
        "    - Filtered versions of X_train, X_val, X_test.\n",
        "    \"\"\"\n",
        "    # Ensure all datasets are DataFrames with column names\n",
        "    if not isinstance(X_train, pd.DataFrame):\n",
        "        X_train = pd.DataFrame(X_train, columns=[f\"Feature_{i}\" for i in range(X_train.shape[1])])\n",
        "    if not isinstance(X_val, pd.DataFrame):\n",
        "        X_val = pd.DataFrame(X_val, columns=[f\"Feature_{i}\" for i in range(X_val.shape[1])])\n",
        "    if not isinstance(X_test, pd.DataFrame):\n",
        "        X_test = pd.DataFrame(X_test, columns=[f\"Feature_{i}\" for i in range(X_test.shape[1])])\n",
        "\n",
        "    # Convert selected indices to column names\n",
        "    selected_feature_names = [f\"Feature_{i}\" for i in selected_features]\n",
        "\n",
        "    # Filter datasets using selected features\n",
        "    X_train_filtered = X_train[selected_feature_names]\n",
        "    X_val_filtered = X_val[selected_feature_names]\n",
        "    X_test_filtered = X_test[selected_feature_names]\n",
        "\n",
        "    return X_train_filtered, X_val_filtered, X_test_filtered\n",
        "\n",
        "# Example usage with selected features\n",
        "selected_features = selected_features_fw  # Replace with the actual selected features list\n",
        "\n",
        "# Filter the datasets\n",
        "X_train_filtered, X_val_filtered, X_test_filtered = filter_features(X_train, X_val, X_test, selected_features)\n",
        "\n",
        "# Verify shapes of filtered datasets\n",
        "print(f\"Filtered X_train shape: {X_train_filtered.shape}\")\n",
        "print(f\"Filtered X_val shape: {X_val_filtered.shape}\")\n",
        "print(f\"Filtered X_test shape: {X_test_filtered.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVjK8h3yKNWZ",
        "outputId": "32327941-21c1-4b84-c7d9-42e1c5b01b11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered X_train shape: (1353, 7)\n",
            "Filtered X_val shape: (194, 7)\n",
            "Filtered X_test shape: (387, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models **without** Feature Selection"
      ],
      "metadata": {
        "id": "PoYy86YjHV4q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkXfk5jNLuI5"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPMkrux4LuI6",
        "outputId": "2057be31-e7ae-43a1-d33e-522c7b51cd2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8087855297157622"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "classifier = RandomForestClassifier(n_estimators=100, max_depth=9,random_state=3)\n",
        "classifier.fit(X_train,Y_train)\n",
        "classifier.score(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwQ5eIDeLuI8"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Cg2MJKpBLuI8",
        "outputId": "7b2f2cc9-aef6-4409-9a1b-b264c1b01c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8294573643410853"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "classifier = GradientBoostingClassifier(n_estimators=100, max_depth=9,random_state=3)\n",
        "classifier.fit(X_train,Y_train)\n",
        "classifier.score(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ocVag6LuI9"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OcAIj5qFLuI9",
        "outputId": "61cbbddf-7055-4651-8fa8-88156195be78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5736434108527132"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train,Y_train)\n",
        "classifier.score(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models **with** Feature selection"
      ],
      "metadata": {
        "id": "dncTkS3JHcam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "GcbDqL4gHgGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(n_estimators=200, max_depth=10,random_state=3) #Fine-tuning manuale\n",
        "classifier.fit(X_train_filtered,Y_train)\n",
        "classifier.score(X_test_filtered,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SM1TFzdHhPa",
        "outputId": "70fb439a-7866-42de-aa7d-f7d6e3fb30fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8165374677002584"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(n_estimators=100, max_depth=9,random_state=3) #Fine-tuning manuale\n",
        "classifier.fit(X_train_filtered,Y_train)\n",
        "classifier.score(X_test_filtered,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7ppWcu5LT6m",
        "outputId": "13f2eb8c-9d88-4543-c268-864e006bdef3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8062015503875969"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting"
      ],
      "metadata": {
        "id": "zIrZzZP5HhWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = GradientBoostingClassifier(n_estimators=100, max_depth=9,random_state=3)\n",
        "classifier.fit(X_train_filtered,Y_train)\n",
        "classifier.score(X_test_filtered,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhwMxmrFHjhp",
        "outputId": "afb0008a-e34d-4b39-d57b-b74886037e29"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.834625322997416"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "e8b0hzp2HkA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train_filtered,Y_train)\n",
        "classifier.score(X_test_filtered,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcij-AIHHmQl",
        "outputId": "f8f2aa5b-fec4-43ec-c1db-7940f63d2fda"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5426356589147286"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}